Классная мысль. И по-человечески — абсолютно правильная.

Ты сейчас предлагаешь перейти от “набор разрозненных настроек” к единому сценарию процесса, где шаги идут последовательно и прозрачно. Это именно то, что обычно резко упрощает сопровождение.
Коротко: моя оценка

Да, идти этим путем — логично и правильно.
Особенно потому, что у вас уже есть зачатки этого подхода:

    в модалке уже есть scenario_json как “сценарий входа”;

    операции уже хранятся как JSON-структура (operations_json → report.steps, report.curl_config);

    cURL уже умеет “логин перед скачиванием” через curl_config.login;

То есть база уже есть — надо сделать ее главной моделью, а не набором частичных костылей.
Почему твоя идея лучше текущего состояния

Сейчас логика размазана по нескольким местам:

    где-то login в scenario_json,

    где-то download steps в report_steps_json,

    где-то cURL config отдельно,

    плюс fallback/ретраи в node.

Из-за этого тебе и сложно видеть “что реально происходит в цепочке”.

Твой подход “единый сценарий = [шаг0, шаг1, шаг2…]” дает:

    Прозрачность — один источник правды.

    Независимость сценариев — каждый форвард живет в своем сценарии.

    Проще отладка — падение всегда на конкретном шаге N.

    Переиспользование движка — один executor для node/curl.

    Контролируемый лог — по шагам, с контекстом.

Как бы я это оформил концептуально (без кода)
1) Единый формат “workflow scenario”

Один JSON-массив шагов, например:

    goto

    fill

    click

    wait_for

    http_request (для cURL/HTTP шага)

    download

    assert (проверки)

И для каждого шага обязательные поля:

    id (уникальный шаг)

    type

    name

    on_error (stop/continue)

    save (что сохранять в контекст: cookie/csrf/token/filepath и т.д.)

2) Единый runtime context

Контекст, который живет между шагами:

    vars: ${login}, ${password}, ${today}, ${today_minus_2y}, ${date_from}/${test_period_from}, ${date_to}/${test_period_to}

    cookies/token/csrf

    last_response / last_url / last_status

    artifacts (screenshot/html/download file)

3) Единый step-лог в файл

На каждый шаг писать структурированный лог:

    timestamp

    scenario_id

    step_id, step_type

    status (start/success/fail)

    duration_ms

    ключевые данные (http code, selector found/not found, file size)

    ссылки на артефакты (html/screenshot/network dump)

Это ровно то, о чем ты сказал: “чтобы видеть обратную связь”.
4) Артефакты отладки

ри ошибке на шаге:

    HTML snapshot страницы

    screenshot

    последние cookies/headers (без секретов)

    (опционально) последние N network requests

Что важно учесть заранее (чтобы не утонуть)

    Версионирование формата
    В JSON должен быть schema_version, иначе потом миграции станут болью.

    Маскирование секретов
    Логины/пароли/токены не должны улетать в plain logs.

    Идемпотентность шагов
    Некоторые шаги нельзя повторять бесконечно (submit формы, download). Нужно явное retry-policy per-step.

    Timeout/Retry per-step
    Глобальный retry — плохо. Лучше на уровне шага.

    Унификация browser/curl
    Не надо два разных мира. Пусть шаги одинаковые, а исполнитель выбирается по executor: browser|http.

Мой практический вердикт

Твоя идея — не “другая”, а стратегически более правильная.
Текущее состояние как раз показывает, что точечные фиксы (CDP, retry, login-merge) дают пользу, но не снимают “непонятность” процесса.
